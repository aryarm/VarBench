import warnings
from pathlib import Path
from snakemake.utils import min_version

##### set minimum snakemake version #####
min_version("6.3.0")

# IMPORT CONFIG VARIABLES
configfile: "config/config.yaml"
# remove any trailing slashes in directories
out = str(Path(config['out']))
data = str(Path(config['data_dir']))
reads = {
    'ont': data+"/NA12878-minion-ul_GRCh38.bam",
    'illumina': data+"/RMNISTHS_30xdownsample.bam"
}
# if we're in development mode, get the reads from DataHub instead of the data dir
if config['develop']:
    for tech in config['develop_in']:
        reads[tech] = config['develop_in'][tech]

# WHICH CALLERS TO RUN?
callers = {
    'gatk', 'freebayes', 'strelka', 'sniffles', 'longshot', 'clair', 'nanosv',
    'nanopolish', 'smartie', 'pbhoney'
}
if config['callers']:
    # double check that the user isn't asking for callers that we can't run
    if not callers.issuperset(config['callers']):
        warnings.warn("Not all of the callers requested can be executed. Proceeding with as many callers as is possible...")
    callers = callers.intersection(config['callers'])

rule all:
   input:
        confusion = out+"/matrix.tsv"

rule download_data:
    params:
        data_dir = data
    output:
        truth_set = data+"/HG001_GRCh38_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.gz",
        illumina = reads['illumina'],
        ont = reads['ont'],
        pacbio = data+"/sorted_final_merged.bam" # TODO: add this to reads dict above
    conda: "envs/default.yaml"
    shell:
        "scripts/download_giab.sh {params.data_dir}"

rule longshot:
    input:
        reads = lambda wildcards: reads[wildcards.tech],
        ref = config['ref']
    output:
        variants = out+"/{tech}/variants/longshot.vcf.gz"
    conda: "envs/longshot.yaml"
    shell:
        "longshot --bam {input.reads} --ref {input.ref} --out {output.variants}"

run clair:
    input:
        bam = expand()
    output:
        vcf = expand()
    params:
        data_dir = str(data)
        model = "resources/clair_models/ont",
        ref = "resources/hg38/hg38.fa",
        output_prefix = "NA12878_ont", 
        sample_name = "NA12878_ont",
    conda: "envs/clair.yaml"
    threads: 4
    shell:
        """
        COMMAND=mktemp 
        CLAIR=$(which clair.py)
        
        python clair.py callVarBamParallel \
        --chkpnt_fn "{params.model}" \
        --ref_fn "{params.ref}" \
        --bam_fn "{input.bam}" \
        --threshold 0.2 \ # what is this?
        --sampleName "{params.sample_name}" \ 
        --output_prefix "{params.output_prefix}" > $COMMAND
        
        # run Clair with 4 concurrencies
        cat $COMMAND | parallel -j{threads}
        
        # Find incomplete VCF files and rerun them
        for i in {params.output_prefix}.*.vcf; do if ! [ -z "$(tail -c 1 "$i")" ]; then echo "$i"; fi ; done | grep -f - $COMMAND | sh
        
        # concatenate vcf files and sort the variants called
        vcfcat {params.output_prefix}.*.vcf | bcftools sort -m 2G | bgziptabix snp_and_indel.vcf.gz
        """
        
rule nanosv:
    input:
        bam = expand()
    output:
        vcf = expand()
    params:
        data_dir = str(data)
        ref = "resources/hg38/hg38.fa",
        output_prefix = "NA12878_ont", 
        sample_name = "NA12878_ont",
    conda: "envs/nanosv.yaml"
    threads: 4
    shell:
        """
        NanoSV -t {threads} -s $(which samtools) {input.bam} -o {output.vcf}
        """

rule nanopolish:
    input:
        fq = expand() 
        bam = expand()
    output:
        vcf = expand()
    params:
        data_dir = str(data)
    conda: "envs/nanopolish.yaml"
    threads: 4
    shell:
        """
        nanopolish variants --reads {input.fq} --bam {input.bam} -p 1 --outfile {output.vcf} 
        """
'''
rule gatk:
    input:
        reads = "NA12878.bam"
        ref_genome = "hg38.fa"
    output:
        variants = "NA12878.vcf.gz"
    conda: "envs/gatk4.yaml"
    shell:
        ""
'''

rule gatk:
    input:
        # single or list of bam files
        bam="NA12878.bam", #Can I change these file names .. no right because of the wrapper 
        ref="hg38.fa"
    output:
        gvcf="NA12878.vcf.gz"
    log:
        "logs/gatk/haplotypecaller/{sample}.log" #Keeping the optional log for now
    resources:
        mem_mb=1024 #Not sure if we need this .. 
    wrapper:
        "0.74.0/bio/gatk/haplotypecaller"

rule freebayes:
    input:
        ref="hg38.fa",
        samples="NA12878.bam",
        # the matching BAI indexes have to present for freebayes
        indexes="NA12878.bam.bai"
    output:
        "NA12878.vcf.gz"  # either .vcf or .bcf
    log:
        "logs/freebayes/{sample}.log"
    params:
        extra="",         # optional parameters
        chunksize=100000, # reference genome chunk size for parallelization (default: 100000)
        normalize=False,  # flag to use bcftools norm to normalize indels
    threads: 2
    wrapper:
        "0.74.0/bio/freebayes"

rule strelka_germline:
    input:
        # the required bam file
        bam="NA12878.bam",
        # path to reference genome fasta and index
        fasta="hg38.fa",
        fasta_index="hg38.fa.fai"
    output:
        # Strelka results - either use directory or complete file path
        directory("strelka/{sample}")
    log:
        "logs/strelka/germline/{sample}.log"
    params:
        # optional parameters
        config_extra="",
        run_extra=""
    threads: 8
    wrapper:
        "0.74.0/bio/strelka/germline"

rule sniffles:
    input:
        reads = "NA12878.bam"
        #ref_genome = "hg38.fa"
    output:
        variants = "NA12878.vcf.gz"
    conda: "envs/gatk4.yaml"
    shell: #./sniffles -m mapped.sort.bam -v output.vcf
        "sniffles -m {input.reads} -v {output.variants}"

